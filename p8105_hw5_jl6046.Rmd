---
title: "P8105 HW5 jl6046"
author: "Brian Jo Hsuan Lee"
date: 2021-11-15
output: github_document
---

Load packages
```{r, message=FALSE}
library(tidyverse)
setwd("~/Desktop/Columbia/Fall_2021/P8105-Data_Science/HW/p8105_hw5_jl6046/")
```

Set knitr options
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Import and tidy the homicide dataset
```{r}
hom_df = 
  read_csv("./data_files/homicide-data.csv", col_types = "cdccfdfffddf") %>% 
  unite(city_state, city, state, sep = ", ") %>% 
  mutate(
    city_state = factor(city_state),
    year = str_extract(reported_date, "^\\d{4}"),
    year = as.factor(year),
    month = str_extract(reported_date, "(?<=^....)\\d{2}"),
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name[]),
    day = str_extract(reported_date, "\\d{2}$"),
    day = as.numeric(day)
  ) %>% 
  select(
    uid, year, month, day, everything(), -reported_date
  )

head(hom_df, 3)
```

Create a table for total and unresolved homicides
```{r}
hom_sum_df = 
  hom_df %>% 
  group_by(city_state) %>% 
  summarize(tot_hom = n(),
            unsol_hom = sum(disposition != "Closed by arrest")) %>% 
  arrange(desc(tot_hom), desc(unsol_hom))

head(hom_sum_df, 3)
```

Compute the proportion of unresolved homicides in Baltimore
```{r}
balt_hom_sum_df =
  hom_sum_df %>% 
  filter(city_state == "Baltimore, MD")

balt_test = 
  prop.test(pull(balt_hom_sum_df, unsol_hom), pull(balt_hom_sum_df, tot_hom)) %>% 
  broom::tidy()

knitr::kable(
  balt_test,
  format = "simple"
)
```

Compute the proportion for all cities
```{r, warning=FALSE}
city_prop_function = function(city){
  city_hom_sum_df =
    hom_sum_df %>% 
    filter(city_state == city)

  test = 
    prop.test(pull(city_hom_sum_df, unsol_hom), pull(city_hom_sum_df, tot_hom)) %>% 
    broom::tidy()
  
  return(test)
}

hom_test_df = 
  hom_sum_df %>% 
  mutate(
    test_res = map(city_state, city_prop_function)
  ) %>% 
  unnest(test_res) %>% 
  select(city_state, estimate, starts_with("conf"))

head(hom_test_df, 3)
```

Graph data using a scatter plot with error bars
```{r}
hom_test_df %>% 
   mutate(
     city_state = fct_reorder(city_state, estimate)
   ) %>% 
  ggplot(aes(x = city_state, y = estimate, color = estimate))+
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Rate of Unsolved Homicides across US Cities",
    x = "City",
    y = "Rate Estimate"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.title = element_blank()
  )
```

## Problem 2

Load and tidy the arm score datasets
```{r, message=FALSE}
setwd("./data_files/data/")

long_df = 
  tibble(
    file_name = list.files(".")
  ) %>% 
  mutate(
    content = map(file_name, read_csv)
  ) %>% 
  unnest(content) %>% 
  separate(file_name, into = c("group", "id"), sep = "_") %>% 
  mutate(
    group = factor(group, levels = c("con", "exp"), labels = c("Control", "Experimental")),
    id = str_replace(id, ".csv", ""),
    id = factor(as.numeric(id))
  ) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "measurement"
  ) 

head(long_df, 3)
```

Plot a spaghetti graph to show the 2 arm scores over time for each of the 10 subjects. The experimental group showed a general trend of increasing scores, whereas the control group does not. 
```{r}
long_df %>% 
  ggplot(aes(x = week, y = measurement)) +
  geom_line(aes(group = id, color = id)) +
  facet_grid(cols = vars(group)) +
  labs(
    title = "Subject Score for Each Arm Over 8 Weeks",
    x = "Week",
    y = "Score",
    color = "Patient ID"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
  )
```

## Problem 3

Set seed to ensure reproducibility and load the tweaked dataset
```{r}
set.seed(33)

iris_with_missing = iris %>% 
  map_df(~ replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

head(iris_with_missing, 5)
```

Write a function that either fills in missing values with the mean of non-missing values or the word "virginica"
```{r}
value_replace = function(vector){
  
  na_list = which(is.na(vector))
  
  if(is.numeric(vector)){
    vector = replace(vector, na_list, mean(vector, trim = 0.10, na.rm=TRUE))
  }
  if(is.character(vector)){
    vector = replace(vector, na_list, "virginica")
  }
  
  return(vector)
}
```

Update the entire dataset using the function
```{r}
iris_value_replaced = 
  iris_with_missing %>% 
  map_df(~ value_replace(.x)) %>% 
  mutate(across(where(is.numeric), ~ round(., 2)))

head(iris_value_replaced, 5)
```


