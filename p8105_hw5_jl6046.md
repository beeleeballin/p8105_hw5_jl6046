P8105 HW5 jl6046
================
Brian Jo Hsuan Lee
2021-11-15

Load packages

``` r
library(tidyverse)
setwd("~/Desktop/Columbia/Fall_2021/P8105-Data_Science/HW/p8105_hw5_jl6046/")
```

Set knitr options

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Import and tidy the homicide dataset

``` r
hom_df = 
  read_csv("./data_files/homicide-data.csv", col_types = "cdccfdfffddf") %>% 
  unite(city_state, city, state, sep = ", ") %>% 
  mutate(
    city_state = factor(city_state),
    year = str_extract(reported_date, "^\\d{4}"),
    year = as.factor(year),
    month = str_extract(reported_date, "(?<=^....)\\d{2}"),
    month = month.name[as.numeric(month)],
    month = factor(month, levels = month.name[]),
    day = str_extract(reported_date, "\\d{2}$"),
    day = as.numeric(day)
  ) %>% 
  select(
    uid, year, month, day, everything(), -reported_date
  )

head(hom_df, 3)
```

    ## # A tibble: 3 × 13
    ##   uid        year  month     day victim_last victim_first victim_race victim_age
    ##   <chr>      <fct> <fct>   <dbl> <chr>       <chr>        <fct>            <dbl>
    ## 1 Alb-000001 2010  May         4 GARCIA      JUAN         Hispanic            78
    ## 2 Alb-000002 2010  Februa…    16 MONTOYA     CAMERON      Hispanic            17
    ## 3 Alb-000003 2010  June        1 SATTERFIELD VIVIANA      White               15
    ## # … with 5 more variables: victim_sex <fct>, city_state <fct>, lat <dbl>,
    ## #   lon <dbl>, disposition <fct>

Create a table for total and unresolved homicides

``` r
hom_sum_df = 
  hom_df %>% 
  group_by(city_state) %>% 
  summarize(tot_hom = n(),
            unsol_hom = sum(disposition != "Closed by arrest")) %>% 
  arrange(desc(tot_hom), desc(unsol_hom))

head(hom_sum_df, 3)
```

    ## # A tibble: 3 × 3
    ##   city_state       tot_hom unsol_hom
    ##   <fct>              <int>     <int>
    ## 1 Chicago, IL         5535      4073
    ## 2 Philadelphia, PA    3037      1360
    ## 3 Houston, TX         2942      1493

Compute the proportion of unresolved homicides in Baltimore

``` r
balt_hom_sum_df =
  hom_sum_df %>% 
  filter(city_state == "Baltimore, MD")

balt_test = 
  prop.test(pull(balt_hom_sum_df, unsol_hom), pull(balt_hom_sum_df, tot_hom)) %>% 
  broom::tidy()

knitr::kable(
  balt_test,
  format = "simple"
)
```

|  estimate | statistic | p.value | parameter |  conf.low | conf.high | method                                               | alternative |
|----------:|----------:|--------:|----------:|----------:|----------:|:-----------------------------------------------------|:------------|
| 0.6455607 |   239.011 |       0 |         1 | 0.6275625 | 0.6631599 | 1-sample proportions test with continuity correction | two.sided   |

Compute the proportion for all cities

``` r
city_prop_function = function(city){
  city_hom_sum_df =
    hom_sum_df %>% 
    filter(city_state == city)

  test = 
    prop.test(pull(city_hom_sum_df, unsol_hom), pull(city_hom_sum_df, tot_hom)) %>% 
    broom::tidy()
  
  return(test)
}

hom_test_df = 
  hom_sum_df %>% 
  mutate(
    test_res = map(city_state, city_prop_function)
  ) %>% 
  unnest(test_res) %>% 
  select(city_state, estimate, starts_with("conf"))

head(hom_test_df, 3)
```

    ## # A tibble: 3 × 4
    ##   city_state       estimate conf.low conf.high
    ##   <fct>               <dbl>    <dbl>     <dbl>
    ## 1 Chicago, IL         0.736    0.724     0.747
    ## 2 Philadelphia, PA    0.448    0.430     0.466
    ## 3 Houston, TX         0.507    0.489     0.526

Graph data using a scatter plot with error bars

``` r
hom_test_df %>% 
   mutate(
     city_state = fct_reorder(city_state, estimate)
   ) %>% 
  ggplot(aes(x = city_state, y = estimate, color = estimate))+
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Rate of Unsolved Homicides across US Cities",
    x = "City",
    y = "Rate Estimate"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 90, hjust = 1),
    legend.title = element_blank()
  )
```

<img src="p8105_hw5_jl6046_files/figure-gfm/unnamed-chunk-7-1.png" width="90%" />

## Problem 2

Load and tidy the arm score datasets

``` r
setwd("./data_files/data/")

long_df = 
  tibble(
    file_name = list.files(".")
  ) %>% 
  mutate(
    content = map(file_name, read_csv)
  ) %>% 
  unnest(content) %>% 
  separate(file_name, into = c("group", "id"), sep = "_") %>% 
  mutate(
    group = factor(group, levels = c("con", "exp"), labels = c("Control", "Experimental")),
    id = str_replace(id, ".csv", ""),
    id = factor(as.numeric(id))
  ) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "measurement"
  ) 

head(long_df, 3)
```

    ## # A tibble: 3 × 4
    ##   group   id    week  measurement
    ##   <fct>   <fct> <chr>       <dbl>
    ## 1 Control 1     1            0.2 
    ## 2 Control 1     2           -1.31
    ## 3 Control 1     3            0.66

Plot a spaghetti graph to show the 2 arm scores over time for each of
the 10 subjects. The experimental group showed a general trend of
increasing scores, whereas the control group does not.

``` r
long_df %>% 
  ggplot(aes(x = week, y = measurement)) +
  geom_line(aes(group = id, color = id)) +
  facet_grid(cols = vars(group)) +
  labs(
    title = "Subject Score for Each Arm Over 8 Weeks",
    x = "Week",
    y = "Score",
    color = "Patient ID"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
  )
```

<img src="p8105_hw5_jl6046_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

## Problem 3

Set seed to ensure reproducibility and load the tweaked dataset

``` r
set.seed(33)

iris_with_missing = iris %>% 
  map_df(~ replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

head(iris_with_missing, 5)
```

    ## # A tibble: 5 × 5
    ##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
    ##          <dbl>       <dbl>        <dbl>       <dbl> <chr>  
    ## 1          5.1         3.5          1.4         0.2 setosa 
    ## 2          4.9         3            1.4        NA   setosa 
    ## 3         NA           3.2         NA           0.2 setosa 
    ## 4         NA          NA            1.5         0.2 <NA>   
    ## 5          5          NA            1.4         0.2 setosa

Write a function that either fills in missing values with the mean of
non-missing values or the word “virginica”

``` r
value_replace = function(vector){
  
  na_list = which(is.na(vector))
  
  if(is.numeric(vector)){
    vector = replace(vector, na_list, mean(vector, trim = 0.10, na.rm=TRUE))
  }
  if(is.character(vector)){
    vector = replace(vector, na_list, "virginica")
  }
  
  return(vector)
}
```

Update the entire dataset using the function

``` r
iris_value_replaced = 
  iris_with_missing %>% 
  map_df(~ value_replace(.x)) %>% 
  mutate(across(where(is.numeric), ~ round(., 2)))

head(iris_value_replaced, 5)
```

    ## # A tibble: 5 × 5
    ##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species  
    ##          <dbl>       <dbl>        <dbl>       <dbl> <chr>    
    ## 1          5.1        3.5          1.4         0.2  setosa   
    ## 2          4.9        3            1.4         1.22 setosa   
    ## 3          5.8        3.2          3.79        0.2  setosa   
    ## 4          5.8        3.04         1.5         0.2  virginica
    ## 5          5          3.04         1.4         0.2  setosa
